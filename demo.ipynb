{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bert-vits2/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/envs/bert-vits2/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from model import Wav2Vec2BertForCantonese\n",
    "from transformers import Wav2Vec2BertProcessor, SeamlessM4TFeatureExtractor, Wav2Vec2CTCTokenizer\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/notebooks/projects/wav2vec2-yue/Wav2Vec2Cantonese/checkpoints/checkpoint-19000\"\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    \"vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\"\n",
    ")\n",
    "tone_tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    \"tone_vocab.json\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    word_delimiter_token=\"|\",\n",
    ")\n",
    "\n",
    "# load processor\n",
    "feature_extractor = SeamlessM4TFeatureExtractor.from_pretrained(model_id)\n",
    "processor = Wav2Vec2BertProcessor(\n",
    "    feature_extractor=feature_extractor, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "model = Wav2Vec2BertForCantonese.from_pretrained(\n",
    "    model_id,\n",
    "    attention_dropout=0.2,\n",
    "    hidden_dropout=0.2,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.0,\n",
    "    layerdrop=0.0,\n",
    "    add_adapter=True,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    ").eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maa4 maa1 go3 jiu4 jiu2 jiu4 jiu4 juk6 zeoi3 maa1 maa4 saang4 tau4 tau4 tau4 tau4 si6 dou6 hok6 hou2 hok6 saang1 hou3 hok6 hou2 hou2 sang1 wut6 hoeng1 gong2 dei6 tit3 maai5 hoeng1 gong2 dei6 dei6 tou4 gam3 daai6 tiu4 ge3 ze1 ze1 mei6 gin3 gwo3 wo3\n"
     ]
    }
   ],
   "source": [
    "test2_audio = \"/notebooks/projects/wav2vec2-yue/test2.wav\"\n",
    "\n",
    "audio_input, _ = librosa.load(test2_audio, sr=16_000)\n",
    "input_features = processor(audio_input, return_tensors=\"pt\", sampling_rate=16_000).input_features[0]\n",
    "\n",
    "output = model.inference(input_features=input_features.unsqueeze(0).cuda(), processor=processor, tone_tokenizer=tone_tokenizer)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-vits2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
